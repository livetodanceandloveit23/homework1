{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/arrhythmia/arrhythmia.data\"\n",
    "data = pd.read_csv(url,header=None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>193</td>\n",
       "      <td>371</td>\n",
       "      <td>174</td>\n",
       "      <td>121</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>202</td>\n",
       "      <td>380</td>\n",
       "      <td>179</td>\n",
       "      <td>143</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>181</td>\n",
       "      <td>360</td>\n",
       "      <td>177</td>\n",
       "      <td>103</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>62.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  270   271  272  273  \\\n",
       "0   75    0  190   80   91  193  371  174  121  -16  ...  0.0   9.0 -0.9  0.0   \n",
       "1   56    1  165   64   81  174  401  149   39   25  ...  0.0   8.5  0.0  0.0   \n",
       "2   54    0  172   95  138  163  386  185  102   96  ...  0.0   9.5 -2.4  0.0   \n",
       "3   55    0  175   94  100  202  380  179  143   28  ...  0.0  12.2 -2.2  0.0   \n",
       "4   75    0  190   80   88  181  360  177  103  -16  ...  0.0  13.1 -3.6  0.0   \n",
       "\n",
       "   274  275  276   277   278  279  \n",
       "0  0.0  0.9  2.9  23.3  49.4    8  \n",
       "1  0.0  0.2  2.1  20.4  38.8    6  \n",
       "2  0.0  0.3  3.4  12.3  49.0   10  \n",
       "3  0.0  0.4  2.6  34.6  61.6    1  \n",
       "4  0.0 -0.1  3.9  25.4  62.8    7  \n",
       "\n",
       "[5 rows x 280 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>202</td>\n",
       "      <td>380</td>\n",
       "      <td>179</td>\n",
       "      <td>143</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>181</td>\n",
       "      <td>360</td>\n",
       "      <td>177</td>\n",
       "      <td>103</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>62.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>167</td>\n",
       "      <td>321</td>\n",
       "      <td>174</td>\n",
       "      <td>91</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  270   271  272  273  \\\n",
       "1   56    1  165   64   81  174  401  149   39   25  ...  0.0   8.5  0.0  0.0   \n",
       "2   54    0  172   95  138  163  386  185  102   96  ...  0.0   9.5 -2.4  0.0   \n",
       "3   55    0  175   94  100  202  380  179  143   28  ...  0.0  12.2 -2.2  0.0   \n",
       "4   75    0  190   80   88  181  360  177  103  -16  ...  0.0  13.1 -3.6  0.0   \n",
       "5   13    0  169   51  100  167  321  174   91  107  ... -0.6  12.2 -2.8  0.0   \n",
       "\n",
       "   274  275  276   277   278  279  \n",
       "1  0.0  0.2  2.1  20.4  38.8    6  \n",
       "2  0.0  0.3  3.4  12.3  49.0   10  \n",
       "3  0.0  0.4  2.6  34.6  61.6    1  \n",
       "4  0.0 -0.1  3.9  25.4  62.8    7  \n",
       "5  0.0  0.9  2.2  13.5  31.1   14  \n",
       "\n",
       "[5 rows x 280 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop([0]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.0</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.471239</td>\n",
       "      <td>0.550885</td>\n",
       "      <td>166.188053</td>\n",
       "      <td>68.170354</td>\n",
       "      <td>88.920354</td>\n",
       "      <td>155.152655</td>\n",
       "      <td>367.207965</td>\n",
       "      <td>169.949115</td>\n",
       "      <td>90.004425</td>\n",
       "      <td>33.676991</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278982</td>\n",
       "      <td>9.048009</td>\n",
       "      <td>-1.457301</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514823</td>\n",
       "      <td>1.222345</td>\n",
       "      <td>19.326106</td>\n",
       "      <td>29.473230</td>\n",
       "      <td>3.880531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.466631</td>\n",
       "      <td>0.497955</td>\n",
       "      <td>37.170340</td>\n",
       "      <td>16.590803</td>\n",
       "      <td>15.364394</td>\n",
       "      <td>44.842283</td>\n",
       "      <td>33.385421</td>\n",
       "      <td>35.633072</td>\n",
       "      <td>25.826643</td>\n",
       "      <td>45.431434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548876</td>\n",
       "      <td>3.472862</td>\n",
       "      <td>2.002430</td>\n",
       "      <td>0.050118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.347531</td>\n",
       "      <td>1.426052</td>\n",
       "      <td>13.503922</td>\n",
       "      <td>18.493927</td>\n",
       "      <td>4.407097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-172.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-28.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-44.200000</td>\n",
       "      <td>-38.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.425000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>-2.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>17.550000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>25.825000</td>\n",
       "      <td>41.125000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>509.000000</td>\n",
       "      <td>381.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>88.800000</td>\n",
       "      <td>115.900000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4           5    \\\n",
       "count  452.000000  452.000000  452.000000  452.000000  452.000000  452.000000   \n",
       "mean    46.471239    0.550885  166.188053   68.170354   88.920354  155.152655   \n",
       "std     16.466631    0.497955   37.170340   16.590803   15.364394   44.842283   \n",
       "min      0.000000    0.000000  105.000000    6.000000   55.000000    0.000000   \n",
       "25%     36.000000    0.000000  160.000000   59.000000   80.000000  142.000000   \n",
       "50%     47.000000    1.000000  164.000000   68.000000   86.000000  157.000000   \n",
       "75%     58.000000    1.000000  170.000000   79.000000   94.000000  175.000000   \n",
       "max     83.000000    1.000000  780.000000  176.000000  188.000000  524.000000   \n",
       "\n",
       "              6           7           8           9    ...         270  \\\n",
       "count  452.000000  452.000000  452.000000  452.000000  ...  452.000000   \n",
       "mean   367.207965  169.949115   90.004425   33.676991  ...   -0.278982   \n",
       "std     33.385421   35.633072   25.826643   45.431434  ...    0.548876   \n",
       "min    232.000000  108.000000    0.000000 -172.000000  ...   -4.100000   \n",
       "25%    350.000000  148.000000   79.000000    3.750000  ...   -0.425000   \n",
       "50%    367.000000  162.000000   91.000000   40.000000  ...    0.000000   \n",
       "75%    384.000000  179.000000  102.000000   66.000000  ...    0.000000   \n",
       "max    509.000000  381.000000  205.000000  169.000000  ...    0.000000   \n",
       "\n",
       "              271         272         273    274         275         276  \\\n",
       "count  452.000000  452.000000  452.000000  452.0  452.000000  452.000000   \n",
       "mean     9.048009   -1.457301    0.003982    0.0    0.514823    1.222345   \n",
       "std      3.472862    2.002430    0.050118    0.0    0.347531    1.426052   \n",
       "min      0.000000  -28.600000    0.000000    0.0   -0.800000   -6.000000   \n",
       "25%      6.600000   -2.100000    0.000000    0.0    0.400000    0.500000   \n",
       "50%      8.800000   -1.100000    0.000000    0.0    0.500000    1.350000   \n",
       "75%     11.200000    0.000000    0.000000    0.0    0.700000    2.100000   \n",
       "max     23.600000    0.000000    0.800000    0.0    2.400000    6.000000   \n",
       "\n",
       "              277         278         279  \n",
       "count  452.000000  452.000000  452.000000  \n",
       "mean    19.326106   29.473230    3.880531  \n",
       "std     13.503922   18.493927    4.407097  \n",
       "min    -44.200000  -38.600000    1.000000  \n",
       "25%     11.450000   17.550000    1.000000  \n",
       "50%     18.100000   27.900000    1.000000  \n",
       "75%     25.825000   41.125000    6.000000  \n",
       "max     88.800000  115.900000   16.000000  \n",
       "\n",
       "[8 rows x 275 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace '?' with NAN \n",
    "data_2 = data.replace(\"?\", np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirming Nulls \n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10, 11, 12, 13, 14], dtype=int64),)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(data_2.isnull().sum())\n",
    "np.where(a > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>444</td>\n",
       "      <td>430</td>\n",
       "      <td>451</td>\n",
       "      <td>76</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>170</td>\n",
       "      <td>101</td>\n",
       "      <td>134</td>\n",
       "      <td>69</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>49</td>\n",
       "      <td>84</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         10   11   12  13   14\n",
       "count   444  430  451  76  451\n",
       "unique  170  101  134  69   63\n",
       "top      52   60   49  84   72\n",
       "freq     13   23    9   3   21"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2[[10,11,12,13,14]].describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10      8\n",
       "11     22\n",
       "12      1\n",
       "13    376\n",
       "14      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2[[10,11,12,13,14]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3 = data_2.drop([13], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452, 279)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4 = data_3.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420, 279)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_4.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Test and Train Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_4.drop([279], axis=1)\n",
    "y = data_4[[279]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# default is 75% / 25% train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regresion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [1, 10, 25, 50, 75, 100]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring='recall_weighted',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = LogisticRegression()\n",
    "param_grid = {'C':[1, 10, 25, 50, 75, 100]}\n",
    "grid_search = GridSearchCV(clf, param_grid, scoring='recall_weighted', return_train_score=True)\n",
    "grid_search.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n",
      "0.7238095238095238\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.070015</td>\n",
       "      <td>0.027256</td>\n",
       "      <td>0.021711</td>\n",
       "      <td>0.029324</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.723810</td>\n",
       "      <td>0.032585</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834146</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.818605</td>\n",
       "      <td>0.823933</td>\n",
       "      <td>0.007224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066306</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.752381</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.032903</td>\n",
       "      <td>2</td>\n",
       "      <td>0.956098</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.962791</td>\n",
       "      <td>0.957090</td>\n",
       "      <td>0.004307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067215</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>25</td>\n",
       "      <td>{'C': 25}</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.707937</td>\n",
       "      <td>0.025782</td>\n",
       "      <td>3</td>\n",
       "      <td>0.990244</td>\n",
       "      <td>0.980952</td>\n",
       "      <td>0.990698</td>\n",
       "      <td>0.987298</td>\n",
       "      <td>0.004491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.076058</td>\n",
       "      <td>0.011163</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>50</td>\n",
       "      <td>{'C': 50}</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.707937</td>\n",
       "      <td>0.021321</td>\n",
       "      <td>3</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.990476</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995199</td>\n",
       "      <td>0.003888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.087901</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>75</td>\n",
       "      <td>{'C': 75}</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.723810</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.018266</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.079281</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.723810</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.701587</td>\n",
       "      <td>0.015718</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.070015      0.027256         0.021711        0.029324       1   \n",
       "1       0.066306      0.008390         0.001276        0.000435      10   \n",
       "2       0.067215      0.001149         0.001329        0.000470      25   \n",
       "3       0.076058      0.011163         0.001114        0.000132      50   \n",
       "4       0.087901      0.002199         0.004382        0.004138      75   \n",
       "5       0.079281      0.005549         0.001680        0.000443     100   \n",
       "\n",
       "       params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0    {'C': 1}           0.681818           0.733333               0.76   \n",
       "1   {'C': 10}           0.672727           0.752381               0.71   \n",
       "2   {'C': 25}           0.681818           0.742857               0.70   \n",
       "3   {'C': 50}           0.681818           0.733333               0.71   \n",
       "4   {'C': 75}           0.681818           0.723810               0.69   \n",
       "5  {'C': 100}           0.690909           0.723810               0.69   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.723810        0.032585                1            0.834146   \n",
       "1         0.711111        0.032903                2            0.956098   \n",
       "2         0.707937        0.025782                3            0.990244   \n",
       "3         0.707937        0.021321                3            0.995122   \n",
       "4         0.698413        0.018266                6            1.000000   \n",
       "5         0.701587        0.015718                5            1.000000   \n",
       "\n",
       "   split1_train_score  split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.819048            0.818605          0.823933         0.007224  \n",
       "1            0.952381            0.962791          0.957090         0.004307  \n",
       "2            0.980952            0.990698          0.987298         0.004491  \n",
       "3            0.990476            1.000000          0.995199         0.003888  \n",
       "4            1.000000            1.000000          1.000000         0.000000  \n",
       "5            1.000000            1.000000          1.000000         0.000000  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Training: 0.94\n",
      "Accuracy: 0.70\n",
      "Recall: 0.69524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.96      0.78        50\n",
      "           2       1.00      0.36      0.53        14\n",
      "           3       0.83      0.83      0.83         6\n",
      "           4       0.75      0.60      0.67         5\n",
      "           5       1.00      0.25      0.40         4\n",
      "           6       0.50      0.50      0.50         4\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       1.00      1.00      1.00         1\n",
      "          10       0.80      0.80      0.80        10\n",
      "          14       0.00      0.00      0.00         2\n",
      "          16       0.00      0.00      0.00         8\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       105\n",
      "   macro avg       0.59      0.48      0.50       105\n",
      "weighted avg       0.67      0.70      0.64       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C = 10)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "\n",
    "y_train_predict = clf.predict(x_train)\n",
    "print('Accuracy of Training: {:.2f}'.format(accuracy_score(y_train, y_train_predict)))\n",
    "y_predict = clf.predict(x_test)\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_predict)))\n",
    "print('Recall: {:.5f}'.format(recall_score(y_test, y_predict, average=\"weighted\")))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b852f742e8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_report = classification_report(y_test, y_predict, output_dict=True)\n",
    "# type(clf_report)\n",
    "%matplotlib inline\n",
    "(pd.DataFrame([v for k,v in clf_report.items()],index= [k for k,v in clf_report.items()])\n",
    "     .iloc[0:11]\n",
    "    .plot(kind='bar', y='f1-score'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_neighbors': [1, 5, 7, 10, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='recall_weighted', verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors':[1, 5, 7, 10, 15]}\n",
    "grid_search = GridSearchCV(knn, param_grid, scoring='recall_weighted', return_train_score=True)\n",
    "grid_search.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 5}\n",
      "0.6222222222222222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008310</td>\n",
       "      <td>0.007523</td>\n",
       "      <td>0.016632</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.565079</td>\n",
       "      <td>0.037789</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.015961</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.609091</td>\n",
       "      <td>0.638095</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>1</td>\n",
       "      <td>0.668293</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0.613953</td>\n",
       "      <td>0.654400</td>\n",
       "      <td>0.029063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.016640</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.606349</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>2</td>\n",
       "      <td>0.648780</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.613953</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.014279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.016937</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_neighbors': 10}</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>3</td>\n",
       "      <td>0.639024</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.595349</td>\n",
       "      <td>0.614632</td>\n",
       "      <td>0.018193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002661</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.015973</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.016204</td>\n",
       "      <td>3</td>\n",
       "      <td>0.629268</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.590698</td>\n",
       "      <td>0.611417</td>\n",
       "      <td>0.015876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.008310      0.007523         0.016632        0.003276   \n",
       "1       0.002328      0.000471         0.015961        0.000801   \n",
       "2       0.002329      0.001247         0.016640        0.002063   \n",
       "3       0.002662      0.001693         0.016937        0.001385   \n",
       "4       0.002661      0.000967         0.015973        0.001406   \n",
       "\n",
       "  param_n_neighbors               params  split0_test_score  \\\n",
       "0                 1   {'n_neighbors': 1}           0.545455   \n",
       "1                 5   {'n_neighbors': 5}           0.609091   \n",
       "2                 7   {'n_neighbors': 7}           0.590909   \n",
       "3                10  {'n_neighbors': 10}           0.581818   \n",
       "4                15  {'n_neighbors': 15}           0.581818   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.533333               0.62         0.565079        0.037789   \n",
       "1           0.638095               0.62         0.622222        0.012073   \n",
       "2           0.609524               0.62         0.606349        0.012073   \n",
       "3           0.619048               0.61         0.603175        0.016064   \n",
       "4           0.609524               0.62         0.603175        0.016204   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                5            1.000000            1.000000   \n",
       "1                1            0.668293            0.680952   \n",
       "2                2            0.648780            0.628571   \n",
       "3                3            0.639024            0.609524   \n",
       "4                3            0.629268            0.614286   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            1.000000          1.000000         0.000000  \n",
       "1            0.613953          0.654400         0.029063  \n",
       "2            0.613953          0.630435         0.014279  \n",
       "3            0.595349          0.614632         0.018193  \n",
       "4            0.590698          0.611417         0.015876  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Training: 0.68\n",
      "Accuracy: 0.51\n",
      "Recall: 0.51429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      1.00      0.66        50\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       1.00      0.17      0.29         6\n",
      "           4       1.00      0.20      0.33         5\n",
      "           5       0.00      0.00      0.00         4\n",
      "           6       0.00      0.00      0.00         4\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       1.00      0.20      0.33        10\n",
      "          14       0.00      0.00      0.00         2\n",
      "          16       0.00      0.00      0.00         8\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       105\n",
      "   macro avg       0.32      0.14      0.15       105\n",
      "weighted avg       0.44      0.51      0.38       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "\n",
    "y_train_predict = knn.predict(x_train)\n",
    "print('Accuracy of Training: {:.2f}'.format(accuracy_score(y_train, y_train_predict)))\n",
    "y_predict = knn.predict(x_test)\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_predict)))\n",
    "print('Recall: {:.5f}'.format(recall_score(y_test, y_predict, average=\"weighted\")))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b853094400>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_report = classification_report(y_test, y_predict, output_dict=True)\n",
    "# type(clf_report)\n",
    "%matplotlib inline\n",
    "(pd.DataFrame([v for k,v in clf_report.items()],index= [k for k,v in clf_report.items()])\n",
    "     .iloc[0:11]\n",
    "    .plot(kind='bar', y='f1-score'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [1, 10, 25, 50, 75, 100]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring='recall_weighted',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = LinearSVC()\n",
    "param_grid = {'C':[1, 10, 25, 50, 75, 100]}\n",
    "grid_search = GridSearchCV(clf, param_grid, scoring='recall_weighted', return_train_score=True)\n",
    "grid_search.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n",
      "0.7111111111111111\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.461456</td>\n",
       "      <td>0.056292</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>4.744949e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.037599</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960976</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.967442</td>\n",
       "      <td>0.961853</td>\n",
       "      <td>0.004250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.405354</td>\n",
       "      <td>0.032605</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>8.164110e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.645455</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.663492</td>\n",
       "      <td>0.016796</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.402956</td>\n",
       "      <td>0.050205</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>2.973602e-07</td>\n",
       "      <td>25</td>\n",
       "      <td>{'C': 25}</td>\n",
       "      <td>0.609091</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.663492</td>\n",
       "      <td>0.040264</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.424232</td>\n",
       "      <td>0.045351</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>2.584933e-05</td>\n",
       "      <td>50</td>\n",
       "      <td>{'C': 50}</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.027894</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.403394</td>\n",
       "      <td>0.028550</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>1.977532e-04</td>\n",
       "      <td>75</td>\n",
       "      <td>{'C': 75}</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.030051</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.409882</td>\n",
       "      <td>0.057715</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>2.608647e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.035896</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.006734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.461456      0.056292         0.001286    4.744949e-04       1   \n",
       "1       0.405354      0.032605         0.001558    8.164110e-04      10   \n",
       "2       0.402956      0.050205         0.001961    2.973602e-07      25   \n",
       "3       0.424232      0.045351         0.001962    2.584933e-05      50   \n",
       "4       0.403394      0.028550         0.001856    1.977532e-04      75   \n",
       "5       0.409882      0.057715         0.001961    2.608647e-05     100   \n",
       "\n",
       "       params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0    {'C': 1}           0.672727           0.761905               0.70   \n",
       "1   {'C': 10}           0.645455           0.685714               0.66   \n",
       "2   {'C': 25}           0.609091           0.685714               0.70   \n",
       "3   {'C': 50}           0.618182           0.685714               0.65   \n",
       "4   {'C': 75}           0.618182           0.666667               0.69   \n",
       "5  {'C': 100}           0.581818           0.666667               0.64   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.711111        0.037599                1            0.960976   \n",
       "1         0.663492        0.016796                2            1.000000   \n",
       "2         0.663492        0.040264                2            1.000000   \n",
       "3         0.650794        0.027894                5            1.000000   \n",
       "4         0.657143        0.030051                4            1.000000   \n",
       "5         0.628571        0.035896                6            1.000000   \n",
       "\n",
       "   split1_train_score  split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.957143            0.967442          0.961853         0.004250  \n",
       "1            1.000000            1.000000          1.000000         0.000000  \n",
       "2            1.000000            1.000000          1.000000         0.000000  \n",
       "3            1.000000            1.000000          1.000000         0.000000  \n",
       "4            1.000000            1.000000          1.000000         0.000000  \n",
       "5            0.985714            1.000000          0.995238         0.006734  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Training: 0.95\n",
      "Accuracy: 0.66\n",
      "Recall: 0.65714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.94      0.77        50\n",
      "           2       0.83      0.36      0.50        14\n",
      "           3       0.83      0.83      0.83         6\n",
      "           4       0.60      0.60      0.60         5\n",
      "           5       1.00      0.25      0.40         4\n",
      "           6       0.40      0.50      0.44         4\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.75      0.60      0.67        10\n",
      "          14       0.00      0.00      0.00         2\n",
      "          16       0.00      0.00      0.00         8\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       105\n",
      "   macro avg       0.46      0.37      0.38       105\n",
      "weighted avg       0.62      0.66      0.61       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(C = 1)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "\n",
    "y_train_predict = clf.predict(x_train)\n",
    "print('Accuracy of Training: {:.2f}'.format(accuracy_score(y_train, y_train_predict)))\n",
    "y_predict = clf.predict(x_test)\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_predict)))\n",
    "print('Recall: {:.5f}'.format(recall_score(y_test, y_predict, average=\"weighted\")))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_depth': [2, 3, 4, 5, 6, 7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='recall_weighted', verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "param_grid = {'max_depth':[2, 3, 4, 5, 6, 7]}\n",
    "grid_search = GridSearchCV(clf, param_grid, scoring='recall_weighted', return_train_score=True)\n",
    "grid_search.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7}\n",
      "0.707936507936508\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018970</td>\n",
       "      <td>0.018361</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.723810</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.704762</td>\n",
       "      <td>0.037359</td>\n",
       "      <td>2</td>\n",
       "      <td>0.746341</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.706977</td>\n",
       "      <td>0.722535</td>\n",
       "      <td>0.017096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>6</td>\n",
       "      <td>0.770732</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.743252</td>\n",
       "      <td>0.020656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009649</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 4}</td>\n",
       "      <td>0.609091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.653968</td>\n",
       "      <td>0.034194</td>\n",
       "      <td>5</td>\n",
       "      <td>0.839024</td>\n",
       "      <td>0.795238</td>\n",
       "      <td>0.758140</td>\n",
       "      <td>0.797467</td>\n",
       "      <td>0.033059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011620</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>0.627273</td>\n",
       "      <td>0.704762</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.692063</td>\n",
       "      <td>0.050845</td>\n",
       "      <td>4</td>\n",
       "      <td>0.887805</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.804651</td>\n",
       "      <td>0.845104</td>\n",
       "      <td>0.033985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011965</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_depth': 6}</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.704762</td>\n",
       "      <td>0.069655</td>\n",
       "      <td>2</td>\n",
       "      <td>0.921951</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.851163</td>\n",
       "      <td>0.886276</td>\n",
       "      <td>0.028902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.013641</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>0.645455</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.707937</td>\n",
       "      <td>0.052042</td>\n",
       "      <td>1</td>\n",
       "      <td>0.941463</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.897674</td>\n",
       "      <td>0.917808</td>\n",
       "      <td>0.018049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.018970      0.018361         0.000986        0.000801   \n",
       "1       0.007301      0.001236         0.001335        0.000468   \n",
       "2       0.009649      0.001221         0.001310        0.000481   \n",
       "3       0.011620      0.000459         0.001668        0.000474   \n",
       "4       0.011965      0.002141         0.000656        0.000464   \n",
       "5       0.013641      0.000932         0.001319        0.000483   \n",
       "\n",
       "  param_max_depth            params  split0_test_score  split1_test_score  \\\n",
       "0               2  {'max_depth': 2}           0.654545           0.723810   \n",
       "1               3  {'max_depth': 3}           0.636364           0.647619   \n",
       "2               4  {'max_depth': 4}           0.609091           0.666667   \n",
       "3               5  {'max_depth': 5}           0.627273           0.704762   \n",
       "4               6  {'max_depth': 6}           0.636364           0.800000   \n",
       "5               7  {'max_depth': 7}           0.645455           0.771429   \n",
       "\n",
       "   split2_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0               0.74         0.704762        0.037359                2   \n",
       "1               0.65         0.644444        0.005997                6   \n",
       "2               0.69         0.653968        0.034194                5   \n",
       "3               0.75         0.692063        0.050845                4   \n",
       "4               0.68         0.704762        0.069655                2   \n",
       "5               0.71         0.707937        0.052042                1   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.746341            0.714286            0.706977   \n",
       "1            0.770732            0.738095            0.720930   \n",
       "2            0.839024            0.795238            0.758140   \n",
       "3            0.887805            0.842857            0.804651   \n",
       "4            0.921951            0.885714            0.851163   \n",
       "5            0.941463            0.914286            0.897674   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.722535         0.017096  \n",
       "1          0.743252         0.020656  \n",
       "2          0.797467         0.033059  \n",
       "3          0.845104         0.033985  \n",
       "4          0.886276         0.028902  \n",
       "5          0.917808         0.018049  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Training: 0.90\n",
      "Accuracy: 0.59\n",
      "Recall: 0.59048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.82      0.77        50\n",
      "           2       0.58      0.50      0.54        14\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.43      0.60      0.50         5\n",
      "           5       1.00      0.50      0.67         4\n",
      "           6       0.50      0.50      0.50         4\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.42      0.50      0.45        10\n",
      "          14       0.00      0.00      0.00         2\n",
      "          16       0.25      0.25      0.25         8\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       105\n",
      "   macro avg       0.35      0.33      0.33       105\n",
      "weighted avg       0.56      0.59      0.57       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth = 7)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "\n",
    "y_train_predict = clf.predict(x_train)\n",
    "print('Accuracy of Training: {:.2f}'.format(accuracy_score(y_train, y_train_predict)))\n",
    "y_predict = clf.predict(x_test)\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_predict)))\n",
    "print('Recall: {:.5f}'.format(recall_score(y_test, y_predict, average=\"weighted\")))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b85520e588>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_report = classification_report(y_test, y_predict, output_dict=True)\n",
    "# type(clf_report)\n",
    "%matplotlib inline\n",
    "(pd.DataFrame([v for k,v in clf_report.items()],index= [k for k,v in clf_report.items()])\n",
    "     .iloc[0:11]\n",
    "    .plot(kind='bar', y='f1-score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tree.pdf'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import graphviz \n",
    "dot_data = tree.export_graphviz(clf, out_file=None,filled=True) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"tree\") \n",
    "# tree.export_graphviz.mro(clf)#.fit(iris.data, iris.target)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [10, 100, 150, 200, 250, 230], 'max_leaf_nodes': [3, 5, 8, 12, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='recall_weighted', verbose=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "param_grid = {'n_estimators':[10, 100, 150, 200, 250, 230], 'max_leaf_nodes':[3, 5, 8, 12, 15] }\n",
    "grid_search = GridSearchCV(clf, param_grid, scoring='recall_weighted', return_train_score=True)\n",
    "grid_search.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_leaf_nodes': 15, 'n_estimators': 150}\n",
      "0.7238095238095238\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017616</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_leaf_nodes': 3, 'n_estimators': 10}</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.015941</td>\n",
       "      <td>25</td>\n",
       "      <td>0.668293</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.638416</td>\n",
       "      <td>0.021434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.097580</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_leaf_nodes': 3, 'n_estimators': 100}</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.013641</td>\n",
       "      <td>25</td>\n",
       "      <td>0.639024</td>\n",
       "      <td>0.604762</td>\n",
       "      <td>0.613953</td>\n",
       "      <td>0.619247</td>\n",
       "      <td>0.014480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.172560</td>\n",
       "      <td>0.035887</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_leaf_nodes': 3, 'n_estimators': 150}</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>29</td>\n",
       "      <td>0.629268</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.613953</td>\n",
       "      <td>0.612820</td>\n",
       "      <td>0.013916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.230102</td>\n",
       "      <td>0.015323</td>\n",
       "      <td>0.015936</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_leaf_nodes': 3, 'n_estimators': 200}</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.606349</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>27</td>\n",
       "      <td>0.643902</td>\n",
       "      <td>0.604762</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.617772</td>\n",
       "      <td>0.018477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.262135</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.020945</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_leaf_nodes': 3, 'n_estimators': 250}</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.606349</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>27</td>\n",
       "      <td>0.629268</td>\n",
       "      <td>0.604762</td>\n",
       "      <td>0.623256</td>\n",
       "      <td>0.619095</td>\n",
       "      <td>0.010428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.234005</td>\n",
       "      <td>0.018706</td>\n",
       "      <td>0.019981</td>\n",
       "      <td>0.004280</td>\n",
       "      <td>3</td>\n",
       "      <td>230</td>\n",
       "      <td>{'max_leaf_nodes': 3, 'n_estimators': 230}</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.015570</td>\n",
       "      <td>30</td>\n",
       "      <td>0.624390</td>\n",
       "      <td>0.604762</td>\n",
       "      <td>0.613953</td>\n",
       "      <td>0.614369</td>\n",
       "      <td>0.008019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.012674</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_leaf_nodes': 5, 'n_estimators': 10}</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.704762</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.038464</td>\n",
       "      <td>20</td>\n",
       "      <td>0.717073</td>\n",
       "      <td>0.704762</td>\n",
       "      <td>0.688372</td>\n",
       "      <td>0.703402</td>\n",
       "      <td>0.011757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.107082</td>\n",
       "      <td>0.004521</td>\n",
       "      <td>0.012348</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_leaf_nodes': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.609091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.641270</td>\n",
       "      <td>0.024511</td>\n",
       "      <td>24</td>\n",
       "      <td>0.712195</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>0.665116</td>\n",
       "      <td>0.684501</td>\n",
       "      <td>0.020098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.159254</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>0.012005</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_leaf_nodes': 5, 'n_estimators': 150}</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.029372</td>\n",
       "      <td>20</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0.683721</td>\n",
       "      <td>0.698794</td>\n",
       "      <td>0.023301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.231017</td>\n",
       "      <td>0.017283</td>\n",
       "      <td>0.021474</td>\n",
       "      <td>0.006428</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_leaf_nodes': 5, 'n_estimators': 200}</td>\n",
       "      <td>0.609091</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.029003</td>\n",
       "      <td>23</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>0.688372</td>\n",
       "      <td>0.698757</td>\n",
       "      <td>0.023824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.433134</td>\n",
       "      <td>0.012252</td>\n",
       "      <td>0.033896</td>\n",
       "      <td>0.014135</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_leaf_nodes': 5, 'n_estimators': 250}</td>\n",
       "      <td>0.627273</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.660317</td>\n",
       "      <td>0.024255</td>\n",
       "      <td>19</td>\n",
       "      <td>0.726829</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.665116</td>\n",
       "      <td>0.687791</td>\n",
       "      <td>0.027724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.316865</td>\n",
       "      <td>0.073591</td>\n",
       "      <td>0.021959</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>5</td>\n",
       "      <td>230</td>\n",
       "      <td>{'max_leaf_nodes': 5, 'n_estimators': 230}</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>0.034971</td>\n",
       "      <td>22</td>\n",
       "      <td>0.726829</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.690892</td>\n",
       "      <td>0.025441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.015688</td>\n",
       "      <td>0.003366</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_leaf_nodes': 8, 'n_estimators': 10}</td>\n",
       "      <td>0.645455</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.034476</td>\n",
       "      <td>16</td>\n",
       "      <td>0.736585</td>\n",
       "      <td>0.719048</td>\n",
       "      <td>0.748837</td>\n",
       "      <td>0.734823</td>\n",
       "      <td>0.012225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.176109</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.009627</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_leaf_nodes': 8, 'n_estimators': 100}</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.695238</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.020596</td>\n",
       "      <td>17</td>\n",
       "      <td>0.775610</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.748837</td>\n",
       "      <td>0.754181</td>\n",
       "      <td>0.015774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.203923</td>\n",
       "      <td>0.013814</td>\n",
       "      <td>0.017613</td>\n",
       "      <td>0.008048</td>\n",
       "      <td>8</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_leaf_nodes': 8, 'n_estimators': 150}</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.704762</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.695238</td>\n",
       "      <td>0.016624</td>\n",
       "      <td>12</td>\n",
       "      <td>0.790244</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.748837</td>\n",
       "      <td>0.760646</td>\n",
       "      <td>0.021071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.272074</td>\n",
       "      <td>0.020662</td>\n",
       "      <td>0.019294</td>\n",
       "      <td>0.002501</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_leaf_nodes': 8, 'n_estimators': 200}</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.723810</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.028614</td>\n",
       "      <td>14</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.739535</td>\n",
       "      <td>0.759055</td>\n",
       "      <td>0.016774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.319707</td>\n",
       "      <td>0.029816</td>\n",
       "      <td>0.031245</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>8</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_leaf_nodes': 8, 'n_estimators': 250}</td>\n",
       "      <td>0.645455</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.031863</td>\n",
       "      <td>14</td>\n",
       "      <td>0.775610</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.739535</td>\n",
       "      <td>0.757429</td>\n",
       "      <td>0.014729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.291417</td>\n",
       "      <td>0.016366</td>\n",
       "      <td>0.019630</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>8</td>\n",
       "      <td>230</td>\n",
       "      <td>{'max_leaf_nodes': 8, 'n_estimators': 230}</td>\n",
       "      <td>0.627273</td>\n",
       "      <td>0.723810</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.679365</td>\n",
       "      <td>0.040521</td>\n",
       "      <td>18</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.748837</td>\n",
       "      <td>0.770247</td>\n",
       "      <td>0.021704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.013960</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_leaf_nodes': 12, 'n_estimators': 10}</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.752381</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.717460</td>\n",
       "      <td>0.025891</td>\n",
       "      <td>3</td>\n",
       "      <td>0.873171</td>\n",
       "      <td>0.861905</td>\n",
       "      <td>0.827907</td>\n",
       "      <td>0.854327</td>\n",
       "      <td>0.019240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.137277</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.009318</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_leaf_nodes': 12, 'n_estimators': 100}</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.692063</td>\n",
       "      <td>0.041290</td>\n",
       "      <td>13</td>\n",
       "      <td>0.843902</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.824158</td>\n",
       "      <td>0.018193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.229052</td>\n",
       "      <td>0.035902</td>\n",
       "      <td>0.012299</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>12</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_leaf_nodes': 12, 'n_estimators': 150}</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.028149</td>\n",
       "      <td>8</td>\n",
       "      <td>0.843902</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.824158</td>\n",
       "      <td>0.018193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.319909</td>\n",
       "      <td>0.026218</td>\n",
       "      <td>0.022257</td>\n",
       "      <td>0.006814</td>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_leaf_nodes': 12, 'n_estimators': 200}</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.028149</td>\n",
       "      <td>8</td>\n",
       "      <td>0.834146</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.818605</td>\n",
       "      <td>0.828695</td>\n",
       "      <td>0.007143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.327766</td>\n",
       "      <td>0.012268</td>\n",
       "      <td>0.022623</td>\n",
       "      <td>0.003313</td>\n",
       "      <td>12</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_leaf_nodes': 12, 'n_estimators': 250}</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.028149</td>\n",
       "      <td>8</td>\n",
       "      <td>0.843902</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.795349</td>\n",
       "      <td>0.822608</td>\n",
       "      <td>0.020266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.311517</td>\n",
       "      <td>0.017960</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>12</td>\n",
       "      <td>230</td>\n",
       "      <td>{'max_leaf_nodes': 12, 'n_estimators': 230}</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.030881</td>\n",
       "      <td>7</td>\n",
       "      <td>0.834146</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.015909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.021609</td>\n",
       "      <td>0.007392</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_leaf_nodes': 15, 'n_estimators': 10}</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.723810</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.701587</td>\n",
       "      <td>0.021862</td>\n",
       "      <td>11</td>\n",
       "      <td>0.921951</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.867339</td>\n",
       "      <td>0.038685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.145459</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_leaf_nodes': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.663636</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.717460</td>\n",
       "      <td>0.039532</td>\n",
       "      <td>3</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.861905</td>\n",
       "      <td>0.846512</td>\n",
       "      <td>0.854025</td>\n",
       "      <td>0.006290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.204173</td>\n",
       "      <td>0.006880</td>\n",
       "      <td>0.013952</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_leaf_nodes': 15, 'n_estimators': 150}</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.723810</td>\n",
       "      <td>0.024128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.907317</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.851163</td>\n",
       "      <td>0.871874</td>\n",
       "      <td>0.025180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.275385</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.017260</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>15</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_leaf_nodes': 15, 'n_estimators': 200}</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.720635</td>\n",
       "      <td>0.028457</td>\n",
       "      <td>2</td>\n",
       "      <td>0.907317</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.851163</td>\n",
       "      <td>0.875049</td>\n",
       "      <td>0.023679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.341769</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.021296</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>15</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_leaf_nodes': 15, 'n_estimators': 250}</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.717460</td>\n",
       "      <td>0.032788</td>\n",
       "      <td>3</td>\n",
       "      <td>0.873171</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.841860</td>\n",
       "      <td>0.865328</td>\n",
       "      <td>0.016895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.333492</td>\n",
       "      <td>0.016455</td>\n",
       "      <td>0.019014</td>\n",
       "      <td>0.002776</td>\n",
       "      <td>15</td>\n",
       "      <td>230</td>\n",
       "      <td>{'max_leaf_nodes': 15, 'n_estimators': 230}</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.717460</td>\n",
       "      <td>0.026618</td>\n",
       "      <td>3</td>\n",
       "      <td>0.887805</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.846512</td>\n",
       "      <td>0.863820</td>\n",
       "      <td>0.017507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.017616      0.004906         0.002002        0.000812   \n",
       "1        0.097580      0.004724         0.008499        0.001763   \n",
       "2        0.172560      0.035887         0.015282        0.003077   \n",
       "3        0.230102      0.015323         0.015936        0.000827   \n",
       "4        0.262135      0.019512         0.020945        0.002179   \n",
       "5        0.234005      0.018706         0.019981        0.004280   \n",
       "6        0.012674      0.000443         0.001988        0.000802   \n",
       "7        0.107082      0.004521         0.012348        0.001333   \n",
       "8        0.159254      0.001935         0.012005        0.000804   \n",
       "9        0.231017      0.017283         0.021474        0.006428   \n",
       "10       0.433134      0.012252         0.033896        0.014135   \n",
       "11       0.316865      0.073591         0.021959        0.003562   \n",
       "12       0.015688      0.003366         0.001980        0.000016   \n",
       "13       0.176109      0.058642         0.009627        0.001204   \n",
       "14       0.203923      0.013814         0.017613        0.008048   \n",
       "15       0.272074      0.020662         0.019294        0.002501   \n",
       "16       0.319707      0.029816         0.031245        0.011783   \n",
       "17       0.291417      0.016366         0.019630        0.003131   \n",
       "18       0.013960      0.000001         0.001974        0.000014   \n",
       "19       0.137277      0.003304         0.009318        0.001257   \n",
       "20       0.229052      0.035902         0.012299        0.000471   \n",
       "21       0.319909      0.026218         0.022257        0.006814   \n",
       "22       0.327766      0.012268         0.022623        0.003313   \n",
       "23       0.311517      0.017960         0.019608        0.002490   \n",
       "24       0.021609      0.007392         0.002328        0.000470   \n",
       "25       0.145459      0.007813         0.010307        0.002619   \n",
       "26       0.204173      0.006880         0.013952        0.001419   \n",
       "27       0.275385      0.011747         0.017260        0.000958   \n",
       "28       0.341769      0.024498         0.021296        0.001707   \n",
       "29       0.333492      0.016455         0.019014        0.002776   \n",
       "\n",
       "   param_max_leaf_nodes param_n_estimators  \\\n",
       "0                     3                 10   \n",
       "1                     3                100   \n",
       "2                     3                150   \n",
       "3                     3                200   \n",
       "4                     3                250   \n",
       "5                     3                230   \n",
       "6                     5                 10   \n",
       "7                     5                100   \n",
       "8                     5                150   \n",
       "9                     5                200   \n",
       "10                    5                250   \n",
       "11                    5                230   \n",
       "12                    8                 10   \n",
       "13                    8                100   \n",
       "14                    8                150   \n",
       "15                    8                200   \n",
       "16                    8                250   \n",
       "17                    8                230   \n",
       "18                   12                 10   \n",
       "19                   12                100   \n",
       "20                   12                150   \n",
       "21                   12                200   \n",
       "22                   12                250   \n",
       "23                   12                230   \n",
       "24                   15                 10   \n",
       "25                   15                100   \n",
       "26                   15                150   \n",
       "27                   15                200   \n",
       "28                   15                250   \n",
       "29                   15                230   \n",
       "\n",
       "                                         params  split0_test_score  \\\n",
       "0     {'max_leaf_nodes': 3, 'n_estimators': 10}           0.590909   \n",
       "1    {'max_leaf_nodes': 3, 'n_estimators': 100}           0.590909   \n",
       "2    {'max_leaf_nodes': 3, 'n_estimators': 150}           0.590909   \n",
       "3    {'max_leaf_nodes': 3, 'n_estimators': 200}           0.590909   \n",
       "4    {'max_leaf_nodes': 3, 'n_estimators': 250}           0.590909   \n",
       "5    {'max_leaf_nodes': 3, 'n_estimators': 230}           0.581818   \n",
       "6     {'max_leaf_nodes': 5, 'n_estimators': 10}           0.618182   \n",
       "7    {'max_leaf_nodes': 5, 'n_estimators': 100}           0.609091   \n",
       "8    {'max_leaf_nodes': 5, 'n_estimators': 150}           0.618182   \n",
       "9    {'max_leaf_nodes': 5, 'n_estimators': 200}           0.609091   \n",
       "10   {'max_leaf_nodes': 5, 'n_estimators': 250}           0.627273   \n",
       "11   {'max_leaf_nodes': 5, 'n_estimators': 230}           0.600000   \n",
       "12    {'max_leaf_nodes': 8, 'n_estimators': 10}           0.645455   \n",
       "13   {'max_leaf_nodes': 8, 'n_estimators': 100}           0.654545   \n",
       "14   {'max_leaf_nodes': 8, 'n_estimators': 150}           0.672727   \n",
       "15   {'max_leaf_nodes': 8, 'n_estimators': 200}           0.654545   \n",
       "16   {'max_leaf_nodes': 8, 'n_estimators': 250}           0.645455   \n",
       "17   {'max_leaf_nodes': 8, 'n_estimators': 230}           0.627273   \n",
       "18   {'max_leaf_nodes': 12, 'n_estimators': 10}           0.690909   \n",
       "19  {'max_leaf_nodes': 12, 'n_estimators': 100}           0.636364   \n",
       "20  {'max_leaf_nodes': 12, 'n_estimators': 150}           0.672727   \n",
       "21  {'max_leaf_nodes': 12, 'n_estimators': 200}           0.672727   \n",
       "22  {'max_leaf_nodes': 12, 'n_estimators': 250}           0.672727   \n",
       "23  {'max_leaf_nodes': 12, 'n_estimators': 230}           0.672727   \n",
       "24   {'max_leaf_nodes': 15, 'n_estimators': 10}           0.672727   \n",
       "25  {'max_leaf_nodes': 15, 'n_estimators': 100}           0.663636   \n",
       "26  {'max_leaf_nodes': 15, 'n_estimators': 150}           0.690909   \n",
       "27  {'max_leaf_nodes': 15, 'n_estimators': 200}           0.681818   \n",
       "28  {'max_leaf_nodes': 15, 'n_estimators': 250}           0.672727   \n",
       "29  {'max_leaf_nodes': 15, 'n_estimators': 230}           0.681818   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.609524               0.63         0.609524        0.015941   \n",
       "1            0.619048               0.62         0.609524        0.013641   \n",
       "2            0.600000               0.62         0.603175        0.012073   \n",
       "3            0.609524               0.62         0.606349        0.012073   \n",
       "4            0.609524               0.62         0.606349        0.012073   \n",
       "5            0.600000               0.62         0.600000        0.015570   \n",
       "6            0.704762               0.63         0.650794        0.038464   \n",
       "7            0.666667               0.65         0.641270        0.024511   \n",
       "8            0.647619               0.69         0.650794        0.029372   \n",
       "9            0.647619               0.68         0.644444        0.029003   \n",
       "10           0.676190               0.68         0.660317        0.024255   \n",
       "11           0.676190               0.67         0.647619        0.034971   \n",
       "12           0.685714               0.73         0.685714        0.034476   \n",
       "13           0.695238               0.70         0.682540        0.020596   \n",
       "14           0.704762               0.71         0.695238        0.016624   \n",
       "15           0.723810               0.69         0.688889        0.028614   \n",
       "16           0.714286               0.71         0.688889        0.031863   \n",
       "17           0.723810               0.69         0.679365        0.040521   \n",
       "18           0.752381               0.71         0.717460        0.025891   \n",
       "19           0.714286               0.73         0.692063        0.041290   \n",
       "20           0.733333               0.73         0.711111        0.028149   \n",
       "21           0.733333               0.73         0.711111        0.028149   \n",
       "22           0.733333               0.73         0.711111        0.028149   \n",
       "23           0.742857               0.73         0.714286        0.030881   \n",
       "24           0.723810               0.71         0.701587        0.021862   \n",
       "25           0.742857               0.75         0.717460        0.039532   \n",
       "26           0.742857               0.74         0.723810        0.024128   \n",
       "27           0.742857               0.74         0.720635        0.028457   \n",
       "28           0.742857               0.74         0.717460        0.032788   \n",
       "29           0.742857               0.73         0.717460        0.026618   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                25            0.668293            0.619048   \n",
       "1                25            0.639024            0.604762   \n",
       "2                29            0.629268            0.595238   \n",
       "3                27            0.643902            0.604762   \n",
       "4                27            0.629268            0.604762   \n",
       "5                30            0.624390            0.604762   \n",
       "6                20            0.717073            0.704762   \n",
       "7                24            0.712195            0.676190   \n",
       "8                20            0.731707            0.680952   \n",
       "9                23            0.731707            0.676190   \n",
       "10               19            0.726829            0.671429   \n",
       "11               22            0.726829            0.671429   \n",
       "12               16            0.736585            0.719048   \n",
       "13               17            0.775610            0.738095   \n",
       "14               12            0.790244            0.742857   \n",
       "15               14            0.780488            0.757143   \n",
       "16               14            0.775610            0.757143   \n",
       "17               18            0.800000            0.761905   \n",
       "18                3            0.873171            0.861905   \n",
       "19               13            0.843902            0.828571   \n",
       "20                8            0.843902            0.828571   \n",
       "21                8            0.834146            0.833333   \n",
       "22                8            0.843902            0.828571   \n",
       "23                7            0.834146            0.833333   \n",
       "24               11            0.921951            0.842857   \n",
       "25                3            0.853659            0.861905   \n",
       "26                1            0.907317            0.857143   \n",
       "27                2            0.907317            0.866667   \n",
       "28                3            0.873171            0.880952   \n",
       "29                3            0.887805            0.857143   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "0             0.627907          0.638416         0.021434  \n",
       "1             0.613953          0.619247         0.014480  \n",
       "2             0.613953          0.612820         0.013916  \n",
       "3             0.604651          0.617772         0.018477  \n",
       "4             0.623256          0.619095         0.010428  \n",
       "5             0.613953          0.614369         0.008019  \n",
       "6             0.688372          0.703402         0.011757  \n",
       "7             0.665116          0.684501         0.020098  \n",
       "8             0.683721          0.698794         0.023301  \n",
       "9             0.688372          0.698757         0.023824  \n",
       "10            0.665116          0.687791         0.027724  \n",
       "11            0.674419          0.690892         0.025441  \n",
       "12            0.748837          0.734823         0.012225  \n",
       "13            0.748837          0.754181         0.015774  \n",
       "14            0.748837          0.760646         0.021071  \n",
       "15            0.739535          0.759055         0.016774  \n",
       "16            0.739535          0.757429         0.014729  \n",
       "17            0.748837          0.770247         0.021704  \n",
       "18            0.827907          0.854327         0.019240  \n",
       "19            0.800000          0.824158         0.018193  \n",
       "20            0.800000          0.824158         0.018193  \n",
       "21            0.818605          0.828695         0.007143  \n",
       "22            0.795349          0.822608         0.020266  \n",
       "23            0.800000          0.822493         0.015909  \n",
       "24            0.837209          0.867339         0.038685  \n",
       "25            0.846512          0.854025         0.006290  \n",
       "26            0.851163          0.871874         0.025180  \n",
       "27            0.851163          0.875049         0.023679  \n",
       "28            0.841860          0.865328         0.016895  \n",
       "29            0.846512          0.863820         0.017507  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Training: 0.83\n",
      "Accuracy: 0.61\n",
      "Recall: 0.60952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.98      0.72        50\n",
      "           2       1.00      0.36      0.53        14\n",
      "           3       0.75      0.50      0.60         6\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.00      0.00      0.00         4\n",
      "           6       0.00      0.00      0.00         4\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       1.00      1.00      1.00         1\n",
      "          10       0.67      0.60      0.63        10\n",
      "          14       0.00      0.00      0.00         2\n",
      "          16       0.00      0.00      0.00         8\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       105\n",
      "   macro avg       0.36      0.31      0.32       105\n",
      "weighted avg       0.52      0.61      0.52       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_leaf_nodes = 15, n_estimators = 100)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "\n",
    "y_train_predict = clf.predict(x_train)\n",
    "print('Accuracy of Training: {:.2f}'.format(accuracy_score(y_train, y_train_predict)))\n",
    "y_predict = clf.predict(x_test)\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_predict)))\n",
    "print('Recall: {:.5f}'.format(recall_score(y_test, y_predict, average=\"weighted\")))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b8553b9550>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_report = classification_report(y_test, y_predict, output_dict=True)\n",
    "# type(clf_report)\n",
    "%matplotlib inline\n",
    "(pd.DataFrame([v for k,v in clf_report.items()],index= [k for k,v in clf_report.items()])\n",
    "     .iloc[0:11]\n",
    "    .plot(kind='bar', y='f1-score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import datasets\n",
    "from IPython.display import Image  \n",
    "from sklearn import tree\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_svmlight_file() got an unexpected keyword argument 'url'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-e1653564059d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdecisionTree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_svmlight_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://archive.ics.uci.edu/ml/machine-learning-databases/arrhythmia/arrhythmia.data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mekg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mekg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: load_svmlight_file() got an unexpected keyword argument 'url'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
